---
marp: true
title: IA Usos i perills a Ã’C.
author: Agusti Moll
paginate: true
theme: gaia
---
<style>
img[alt~="center"] {
  display: block;
  margin: 0 auto;
}
</style>
# ğŸ‘¥ IA com a Aliat Social?

- **QuÃ¨ Ã©s la intelÂ·ligÃ¨ncia artificial?**  

- **Beneficis de la IA en el Tercer Sector i Projectes Socials**  
  - OptimitzaciÃ³ de processos interns
  - FacilitaciÃ³ de la comunicaciÃ³
  - Suport a la presa de decisions
  - Accessibilitat

- **Context de la causa catalana:**
  - DifusiÃ³ de la llengua
  - Lluita contra la desinformaciÃ³
  - Seguretat digital

<!--
**Notes:**  
- La IntelÂ·ligÃ¨ncia Artificial (IA) es refereix a sistemes informÃ tics capaÃ§os d'executar tasques que normalment requereixen intelÂ·ligÃ¨ncia humana, com ara el reconeixement de patrons, la presa de decisions o la generaciÃ³ de llenguatge. Des de les seves primeres investigacions als anys 50 fins als models actuals basats en xarxes neuronals, la IA ha evolucionat per convertir-se en una eina fonamental en mÃºltiples sectors.
- Beneficis de la IA en el Tercer Sector i Projectes Socials
  - OptimitzaciÃ³ de processos interns: AutomatitzaciÃ³ de tasques administratives com la gestiÃ³ de bases de dades o el seguiment de projectes.
  - FacilitaciÃ³ de la comunicaciÃ³: CreaciÃ³ de resums automÃ tics, assistÃ¨ncia en la redacciÃ³ de materials de sensibilitzaciÃ³ o gestiÃ³ de xarxes socials.
  - Suport a la presa de decisions: AnÃ lisi de dades per a millorar estratÃ¨gies de captaciÃ³ de fons o lâ€™impacte de campanyes socials.
  - Accessibilitat: Aplicacions que milloren lâ€™accÃ©s a la informaciÃ³ per a persones amb discapacitat visual o auditiva.

- Context de la causa catalana i la tecnologia com a eina estratÃ¨gica
La IA pot jugar un paper clau en la defensa de drets socials i la promociÃ³ de la llengua i cultura catalana:

  - PreservaciÃ³ i difusiÃ³ de la llengua: Sistemes de traducciÃ³ automÃ tica i correcciÃ³ en catalÃ .
  - Lluita contra la desinformaciÃ³: AnÃ lisi de notÃ­cies falses i identificaciÃ³ d'informaciÃ³ manipulada.
  - Seguretat digital: Eines de protecciÃ³ de dades i comunicaciÃ³ xifrada per garantir la privacitat de les entitats.
-->
---
# ğŸ” Conceptes

**QuÃ¨ Ã©s la IA, l'aprenentatge automÃ tic i el *deep learning***  
  
**ğŸš€ Aplicacions prÃ ctiques en lâ€™entitat:**  
  - AutomatitzaciÃ³ de tasques administratives
  - Suport en la creaciÃ³ de continguts

<!--   
**Notes:**  
Concepte:
Cercles concentrics.

**IntelÂ·ligÃ¨ncia Artificial (IA)*: Fa referÃ¨ncia a sistemes informÃ tics que poden realitzar tasques que normalment requereixen intelÂ·ligÃ¨ncia humana, com ara la presa de decisions, el reconeixement d'imatges o el processament del llenguatge.

**Aprenentatge automÃ tic (Machine Learning - ML)**: Ã‰s una subcategoria de la IA on els sistemes aprenen patrons a partir de dades i fan prediccions sense ser explÃ­citament programats. Un exemple prÃ ctic podria ser un sistema que categoritza correus electrÃ²nics com a "importants" o "brossa" en funciÃ³ dels missatges que lâ€™usuari obre mÃ©s sovint.

**Deep Learning**: Ã‰s una branca de lâ€™aprenentatge automÃ tic que utilitza xarxes neuronals artificials per processar grans volums de dades. Per exemple, el reconeixement facial en xarxes socials o la traducciÃ³ automÃ tica en temps real.

** Exemple: 

Aplicacions prÃ ctiques en una entitat de causa
Les entitats socials poden aprofitar la IA per millorar l'eficiÃ¨ncia i optimitzar recursos en diferents Ã mbits:

**AutomatitzaciÃ³ de tasques administratives**

- Eines dâ€™IA poden ajudar a organitzar grans volums de dades sobre socis, donacions o projectes.
- Exemples: Sistemes que classifiquen documents automÃ ticament o generen resums d'informes.
**Suport en la creaciÃ³ de continguts**

- Assistents dâ€™IA poden suggerir textos per comunicats de premsa, publicacions a xarxes socials o butlletins informatius.
- Exemples: IA que analitza el sentiment de comentaris a xarxes socials per ajustar el to de la comunicaciÃ³.

-->
---

# ğŸ›  Eines d'IA per a l'Entitat

  - **Plataformes conversacionals**: [ChatGPT](https://chatgpt.com), [Claude](https://claude.ai/), [Deepseek](https://chat.deepseek.com/) poden ajudar en la redacciÃ³ de textos, resum de documents i suport en la presa de decisions.
  - **Reconeixement de veu i imatge**: [Whisper](https://github.com/openai/whisper) permet transcriure Ã udio a text amb gran precisiÃ³, [Otter.ia](https://otter.ai/) facilita la transcripciÃ³ i resum de reunions. 
  - **GeneraciÃ³ de continguts multimÃ¨dia**: [Canva amb IA](https://www.canva.com/es_es/generador-imagenes-ia/) crear dissenys automÃ ticament, [Descript](https://web.descript.com/) facilita l'ediciÃ³ de vÃ­deo i Ã udio amb IA. 

---

# ğŸ§° Recursos d'IA per a l'Entitat
- **Recursos formatius:**
  Cursos, webinars i manuals <sup>[1](https://www.youtube.com/playlist?list=PL6kQim6ljTJuDrH3yPIxfrbHRBm_o8kxB)</sup> per a la formaciÃ³ contÃ­nua, amb especial atenciÃ³ a recursos en catalÃ .
- **Entorns de desenvolupament:**  
  IntroducciÃ³ a Python, biblioteques com TensorFlow o PyTorch i plataformes com Google Colab.


<!--
 Nosaltres ja fem servir la IA per analitzar XXSS i determinar si els missatges que fan refencia a nosaltres son positius o negatius i quina relevancia tenen.
-->
---
# ğŸ¯ Casos prÃ ctic d'altres entitats
- **Creu roja** sembla que utilitza IA per optimitzar la distribuciÃ³ dâ€™ajuda humanitÃ ria en zones afectades per desastres naturals.[1](https://www2.cruzroja.es/ca/web/ahora/-/inteligencia-artificial-humanitaria-humanista) 
- **Amnistia Internacional** sembla que fa servir IA per detectar discursos dâ€™odi i desinformaciÃ³ a les xarxes socials.
- **Banc dels Aliments** podrien estar provat models predictius per optimitzar la recollida i distribuciÃ³ dâ€™aliments segons la demanda.




---
# ğŸ¦ **Salamadra** un model del BSC
![width:600px center](img/corpus_language_1.1.png)
En el marc del projecte [ALIA](https://alia.gob.es/), s'han publicat uns [models de text](https://langtech-bsc.gitbook.io/alia-kit/modelos/modelos-de-texto). 

---

# â€‹ğŸ¬â€‹ Enginyeria de Prompt 


**QuÃ¨ Ã©s un prompt?**
Un prompt Ã©s el conjunt d'instruccions o text que donem a una IA per obtenir una resposta o generaciÃ³ concreta. Pot ser una pregunta, una descripciÃ³, una ordre o fins i tot un conjunt de criteris detallats.
**PerquÃ¨ Ã©s tant important?**
Qualitat de la resposta, Control i personalitzaciÃ³ , EficÃ cia i temps, Etica i seguretat.
**Recurs**
[Guia d'Enginyeria de Prompts](https://www.promptingguide.ai/ca)

<!---
Notes:
ğŸ”¹ Qualitat de la resposta â†’ Un bon prompt guia la IA per donar respostes mÃ©s precises i Ãºtils.
ğŸ”¹ Control i personalitzaciÃ³ â†’ Permet afinar els resultats segons necessitats especÃ­fiques.
ğŸ”¹ EficÃ cia i temps â†’ Evita respostes vagues i redueix la necessitat de repetir consultes.
ğŸ”¹ Ãˆtica i seguretat â†’ Un prompt ben formulat pot evitar biaixos i respostes problemÃ tiques.

-->

---

# ğŸ›  Exemple enginyeria de prompt:

**Mala prÃ ctica**
  *"Explica'm la histÃ²ria de Catalunya."*

**Bona prÃ ctica**
  *"Fes-me un resum en 5 punts clau de la histÃ²ria de Catalunya amb Ã¨mfasi en la seva evoluciÃ³ polÃ­tica."*


---

# ğŸ›¡ Seguretat: Riscos en lâ€™Ãºs de la IA (I)
### Amenaces en la seguretat informÃ tica
  - ğŸ¥· **Ciberatacs**: Els atacants poden introducir dades malicioses en l'entrenament del model (*Data Poisoning*). O la generaciÃ³ de continguts, amb tÃ¨cniques com els "deepfakes", amb l'objectius de manipular l'opinio pÃºblica (*Spoofing*)
  - ğŸ›  **Sistemes vulnerables**: Algoritmes mal protegits o amb biaixos en les dades d'entrenament poden generar resultats esbiaixats o perjudicials.(*Biaixos en l'algoritmes*). Molt models funcionen com "caixes negres" on els porcessos interns son opacs (*Falta de transparÃ¨ncia*)

<!--
**Notes**
  Exemples de:
  - **Data Poisoing**: En sistemes de reconeixement facial s'han detectat casos on petites modificacions en les imatges permeten que persones no autoritzades siguin reconegudes com a legÃ­times.
  - **Spoofing**: Febrer del 2024, a Hong Kong: un treballador d'una multinacional va pagar 25 milions de dÃ²lars, tal com havia acordat en una reuniÃ³ amb una altra empresa. Els assistents, perÃ², eren deepfakes fets amb IA. Juny del 2023, als Estats Units: una mare va rebre una trucada. A l'altra banda del telÃ¨fon parlava la seva filla dient que l'havien segrestat [IA darrera del 40% de les ciberestafes](http://archive.today/qnsUs). PerÃ² no ho era, la seva veu l'havien generat amb IA. Els atacs utilitzant al IA han aumentat des del 2022 un 370%, i es calcula que  
  - **Biaixos en l'algoritmes**
  - **Falta de transparÃ¨ncia** : Els models no oberts, po
Aquests exemples ressalten la importÃ ncia de desenvolupar i implementar sistemes d'IA amb mesures robustes de seguretat i Ã¨tica, per tal de minimitzar riscos i protegir tant les dades com els usuaris.

-->

---
# ğŸ›¡ Seguretat: Riscos en lâ€™Ãºs (II)

### DependÃ¨ncia Excessiva i DeshumanitzaciÃ³
- ğŸ“‰ **PÃ¨rdua de criteri humÃ **: DelegaciÃ³ excessiva de decisions crÃ­tiques a la IA.
- ğŸ¥ **Impacte en sectors sensibles**: Errors en IA mÃ¨dica, judicial o financera poden tenir conseqÃ¼Ã¨ncies greus.
- ğŸ¤– **ReducciÃ³ de la creativitat i pensament crÃ­tic**: AutomatitzaciÃ³ excessiva que limita la intervenciÃ³ humana.

---

# ğŸ›¡ Seguretat: Riscos en lâ€™Ãºs (III)

### Impacte en la privacitat
- ğŸ“· **Recollida massiva de dades**: IA que captura informaciÃ³ personal sense consentiment explÃ­cit.
- ğŸ  **Seguiment constant**: Riscos en sistemes de videovigilÃ ncia i rastreig de dades.
- ğŸ“¡ **Identitat digital en perill**: Possibilitat de suplantaciÃ³ total de persones en entorns digitals.

<!---
**Notes:**  
- IlÂ·lustra amb exemples prÃ ctics el mal Ãºs d'algoritmes en altres contextos.  
- ReforÃ§a la necessitat d'una gestiÃ³ proactiva dels riscos, tant tecnolÃ²gics com Ã¨tics.
-->
---
# ğŸ›¡ Seguretat: Riscos en lâ€™Ãºs (IV)

### Riscos en llengÃ¼es minoritzades
- ğŸ—£ï¸ **InfrarepresentaciÃ³ en els models**: Si una llengua no Ã©s prou present en els corpus dâ€™entrenament, els models poden generar respostes incoherents o incorrectes.
- ğŸ›ï¸ **PÃ¨rdua de diversitat lingÃ¼Ã­stica**: Les llengÃ¼es majoritÃ ries en el corpus poden influir en la generaciÃ³ de text en llengÃ¼es minoritzades, provocant errors gramaticals, lÃ¨xics o estructurals.

---
# ğŸ›¡ Seguretat: Riscos en lâ€™Ãºs (V)

### Invencions i AlÂ·lucinacions de la IA
- ğŸŒ¡**Temperatura mal ajustada**:  Un nivell de creativitat massa alt pot fer que la IA generi contingut menys fiable i mÃ©s imaginatiu, augmentant el risc dâ€™alÂ·lucinacions.
- ğŸ¤¯ **Falsedats amb to convincent**: La IA pot generar informaciÃ³ incorrecta amb un estil que sembla fiable.
- ğŸ“š **ReferÃ¨ncies inventades**: CreaciÃ³ de cites acadÃ¨miques, estudis o fets histÃ²rics inexistents.

---
# âœ… Bones PrÃ ctiques
- ğŸ› **PolÃ­tiques internes i codi Ã¨tic:**  
  - Definir valors i principis clars per a lâ€™Ãºs de la IA.  
  - Exemples de codis Ã¨tics d'[altres entitats](https://andorra-digital.com/images/pdf/recursos/codi%20etic%20IA.pdf), empreses.
- ğŸ›¡ï¸ **Protocols de seguretat:**  
  - Auditoria regular dels sistemes dâ€™IA.  
  - Protocols dâ€™accÃ©s i control de dades.
- ğŸ“ **FormaciÃ³ contÃ­nua:**  
  - Tallers, sessions en seguretat informÃ tica i Ã¨tica de la IA.  
  - ColÂ·laboraciÃ³ amb experts externs.

<!--
**Notes:**  
- Proposa la creaciÃ³ dâ€™un comitÃ¨ intern per supervisar lâ€™Ãºs de la IA.  
- Discutir la importÃ ncia del manteniment constant i la revisiÃ³ periÃ²dica dels sistemes.

ğŸ“Œ Com mitigar-ho?
âœ”ï¸ Exigir transparÃ¨ncia en els models i bases de dades.
âœ”ï¸ Aplicar auditories Ã¨tiques en el desenvolupament i Ãºs dâ€™IA.
âœ”ï¸ Establir regulacions clares per a un Ãºs responsable.
-->

---
# ğŸ› PolÃ­tiques internes i codi Ã¨tic

Basat en [Catalonia.AI](https://politiquesdigitals.gencat.cat/ca/economia/catalonia-ai/) i marc regulatori de [la IA del parlament europeu](https://eur-lex.europa.eu/legal-content/ES/TXT/?uri=CELEX:32024R1689) hauriem de:
- **Integrar els principis Ã¨tic fonamentals**: Respecte per l'autonomia humana, prevenciÃ³ de danys, equitat i explicabilitat.
- **Definir els requisits per a una IA fiable**: SupervisiÃ³ humana, robustesa tÃ¨cnica i seguretat, gestiÃ³ de dades i privacitat, transparÃ¨ncia, no discriminaciÃ³, impacte social-ambiental i rendiciÃ³ de comptes.


<!--
**Notes**
Catalonia.AI => EstratÃ¨gia d'IntelÂ·ligÃ¨ncia Artificial a Catalunya
### Principis Ã¨tics fonamentals
- Respecte per lâ€™autonomia humana â€“ Els sistemes d'IA han de potenciar les capacitats humanes sense coaccionar, enganyar o manipular les persones.
- PrevenciÃ³ de danys â€“ La IA ha de garantir la seguretat fÃ­sica i mental de les persones i evitar usos malintencionats.
-Equitat â€“ Sâ€™ha de garantir una distribuciÃ³ justa dels beneficis de la IA i evitar biaixos discriminatoris.
- Explicabilitat â€“ Els sistemes d'IA han de ser transparents i les seves decisions han de poder ser explicades a les persones afectadesâ€‹Estrategia_IA_Catalunyaâ€¦.
###Requisits per a una IA fiable
- SupervisiÃ³ humana: La IA ha de complementar la presa de decisions humana i assegurar mecanismes de supervisiÃ³.
- Robustesa tÃ¨cnica i seguretat: Els sistemes han de ser segurs, fiables i protegits contra vulnerabilitats.
- GestiÃ³ de dades i privacitat: ProtecciÃ³ de la informaciÃ³ de les persones i garanties de qualitat i integritat de les dades.
- TransparÃ¨ncia: Cal assegurar la traÃ§abilitat de les dades i la identificaciÃ³ clara dels sistemes d'IA.
- Diversitat i no discriminaciÃ³: Disseny inclusiu i eliminaciÃ³ de biaixos discriminatoris.
- Impacte social i ambiental: La IA ha de ser sostenible i fomentar el benestar social.
- RendiciÃ³ de comptes: Han dâ€™existir mecanismes per garantir la responsabilitat dels desenvolupadors i usuaris de la IA.

-->

---

# ğŸ“„ Problemes d'IA i el catalÃ 

Com ja hem anat veient i atÃ¨s que el seu corpus tÃ© molt poc catalÃ  **No entenen bÃ© el catalÃ ** i **Barrejar-lo amb altres idiomes**.

*Exemple*
``` 
> Bon dia, com estÃ s?
"Estoy bien."
``` 



<!--
- **RecapitulaciÃ³:**  
  Repassa els conceptes claus, eines, riscos i bones prÃ ctiques presentats.
- **LÃ­nies dâ€™acciÃ³ immediates:**  
  - Propostes per iniciar projectes pilots amb la IA.  
  - Establir un pla de formaciÃ³ continuada i monitoritzaciÃ³ de la seguretat.
- **Foment de la colÂ·laboraciÃ³:**  
  - Treball conjunt amb altres entitats i experts per compartir experiÃ¨ncies.  
  - CreaciÃ³ d'una xarxa de suport intern per a la gestiÃ³ dels riscos.

**Notes:**  
- Enfatitza que la integraciÃ³ de la IA Ã©s un procÃ©s continu i d'adaptaciÃ³ constant.  
- Convida els assistents a aportar idees i comprometre's amb mesures de seguretat i Ã¨tica.
-->
---

# â‰ï¸ Preguntes i debat final

<!-- 
- Espai per a Q&A: Obrir un espai per respondre preguntes i aclarir dubtes.
- DinÃ mica de debat: Proposa un debat sobre casos prÃ ctics o dilemes Ã¨tics.

**Notes:**  
- Anima als participants a compartir les seves experiÃ¨ncies o inquietuds.  
- Facilita un ambient de diÃ leg obert sobre com avanÃ§ar de manera segura i responsable.
-->